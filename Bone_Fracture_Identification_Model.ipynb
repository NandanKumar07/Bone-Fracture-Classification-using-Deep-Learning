{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NandanKumar07/Bone-Fracture-Classification-using-Deep-Learning/blob/main/Bone_Fracture_Identification_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "VG1AwXghmjPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sYGjS4Spm0qB",
        "outputId": "6ab6339e-308e-4819-911a-61e738f3e859",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "bzwyYwQ_mo__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "PCp9Z87xpFMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80b01ae5-bd25-4c06-a9a1-88da92cf267e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/drive/MyDrive/kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "VMF98MI7pOwL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46227d86-6fdc-46ab-937f-d41a51fdb2a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d vuppalaadithyasairam/bone-fracture-detection-using-xrays/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVPUXJtPpyjK",
        "outputId": "6b64b7d1-2f5b-4212-d037-9390bcb58b0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/vuppalaadithyasairam/bone-fracture-detection-using-xrays/versions/\n",
            "License(s): unknown\n",
            "Downloading bone-fracture-detection-using-xrays.zip to /content\n",
            " 99% 171M/172M [00:00<00:00, 216MB/s]\n",
            "100% 172M/172M [00:00<00:00, 195MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip fracture-classification-dataset.zip\n",
        "!unzip bone-fracture-detection-using-xrays.zip"
      ],
      "metadata": {
        "id": "DZtO1htlqwf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "tsSLAoDQsgd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "qrMpRwsirlE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Data:"
      ],
      "metadata": {
        "id": "5dBAAdRstBGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_images(image_folder, target_size, grayscale=False):\n",
        "    images = []\n",
        "    for filename in os.listdir(image_folder):\n",
        "        # Construct the full path to the image file\n",
        "        img_path = os.path.join(image_folder, filename)\n",
        "        # Load the image using OpenCV\n",
        "        img = cv2.imread(img_path)\n",
        "        # Resize the image to the target size\n",
        "        img_resized = cv2.resize(img, target_size)\n",
        "        # Convert the image to grayscale if grayscale=True\n",
        "        if grayscale:\n",
        "            img_resized = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
        "        # Append the preprocessed image to the list\n",
        "        images.append(img_resized)\n",
        "    # Convert the list of images to a NumPy array\n",
        "    images_array = np.array(images)\n",
        "    return images_array\n"
      ],
      "metadata": {
        "id": "x6CY9jges6ZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the target size\n",
        "target_size = (225, 225)\n",
        "\n",
        "fractured_images_color = load_and_preprocess_images('boneData/train/fractured', target_size, grayscale=False)\n",
        "non_fractured_images_color = load_and_preprocess_images('boneData/train/not fractured', target_size, grayscale=False)\n",
        "\n",
        "# Concatenate fractured and non-fractured color images into a single array\n",
        "all_images_color = np.concatenate([fractured_images_color, non_fractured_images_color], axis=0)\n",
        "\n",
        "fractured_images_grayscale = load_and_preprocess_images('boneData/train/fractured', target_size, grayscale=True)\n",
        "non_fractured_images_grayscale = load_and_preprocess_images('boneData/train/not fractured', target_size, grayscale=True)\n",
        "\n",
        "# Concatenate fractured and non-fractured grayscale images into a single array\n",
        "all_images_grayscale = np.concatenate([fractured_images_grayscale, non_fractured_images_grayscale], axis=0)\n",
        "\n",
        "# Print the shapes of the resulting arrays\n",
        "print(\"Shape of the array containing all color images:\", all_images_color.shape)\n",
        "print(\"Shape of the array containing all grayscale images:\", all_images_grayscale.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaLfEuXQyMIC",
        "outputId": "f47a1faa-3d27-4f4a-b939-7d53b6bb8117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the array containing all color images: (8863, 225, 225, 3)\n",
            "Shape of the array containing all grayscale images: (8863, 225, 225)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the grayscale images\n",
        "all_img = all_images_grayscale / 255.0"
      ],
      "metadata": {
        "id": "12Motgi4yOLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the number of fractured and non-fractured images\n",
        "num_fractured_images = fractured_images_grayscale.shape[0]\n",
        "num_non_fractured_images = non_fractured_images_grayscale.shape[0]\n",
        "\n",
        "# Create binary labels\n",
        "y_fractured = np.ones((num_fractured_images,), dtype=int)  # Label 1 for fractured images\n",
        "y_non_fractured = np.zeros((num_non_fractured_images,), dtype=int)  # Label 0 for non-fractured images\n",
        "\n",
        "# Concatenate binary labels\n",
        "y = np.concatenate([y_fractured, y_non_fractured], axis=0)\n",
        "\n",
        "# Print the shape of the labels array\n",
        "print(\"Shape of the labels array:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdF90U3Nv7fL",
        "outputId": "9afcd70f-7842-4d05-9db1-677d7c457d20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the labels array: (8863,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp4EJnDGyQOz",
        "outputId": "7069187f-8bdd-48f4-fa06-50210ece0981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(all_images_grayscale, y, test_size = 0.20, random_state = 42)\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size = 0.25, random_state = 42)\n",
        "\n",
        "# Print the shapes of the resulting arrays\n",
        "print(\"Shape of x_train:\", x_train.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of x_valid:\", x_valid.shape)\n",
        "print(\"Shape of y_valid:\", y_valid.shape)\n",
        "print(\"Shape of x_test:\", x_test.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoQ5CPMsyR88",
        "outputId": "17636024-fef1-4949-bb90-3baa86e56b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_train: (5317, 225, 225)\n",
            "Shape of y_train: (5317,)\n",
            "Shape of x_valid: (1773, 225, 225)\n",
            "Shape of y_valid: (1773,)\n",
            "Shape of x_test: (1773, 225, 225)\n",
            "Shape of y_test: (1773,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "FWHf0RMg2vju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ],
      "metadata": {
        "id": "2O6qxjOw3BR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation = 'relu', input_shape = (225, 225, 1)),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Conv2D(64, (3, 3), activation = 'relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "CHVm4Tgn3V-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',  # Use the SGD optimizer\n",
        "              loss='binary_crossentropy',  # Binary cross-entropy loss for binary classification\n",
        "              metrics=['accuracy'])  # Monitor accuracy during training\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train.reshape(-1, 225, 225, 1), y_train, epochs=10, batch_size=64, validation_data=(x_valid.reshape(-1, 225, 225, 1), y_valid))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(x_test.reshape(-1, 225, 225, 1), y_test)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl2WKEsM6dMQ",
        "outputId": "36fb7887-5f22-43ae-a0bc-86d1e8303a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "84/84 [==============================] - 18s 108ms/step - loss: 11.2140 - accuracy: 0.6445 - val_loss: 0.5220 - val_accuracy: 0.7349\n",
            "Epoch 2/10\n",
            "84/84 [==============================] - 8s 90ms/step - loss: 0.3410 - accuracy: 0.8537 - val_loss: 0.3893 - val_accuracy: 0.8223\n",
            "Epoch 3/10\n",
            "84/84 [==============================] - 7s 89ms/step - loss: 0.1624 - accuracy: 0.9381 - val_loss: 0.2103 - val_accuracy: 0.9278\n",
            "Epoch 4/10\n",
            "84/84 [==============================] - 8s 90ms/step - loss: 0.0770 - accuracy: 0.9690 - val_loss: 0.2380 - val_accuracy: 0.9233\n",
            "Epoch 5/10\n",
            "84/84 [==============================] - 7s 88ms/step - loss: 0.0536 - accuracy: 0.9797 - val_loss: 0.1251 - val_accuracy: 0.9662\n",
            "Epoch 6/10\n",
            "84/84 [==============================] - 7s 89ms/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.1937 - val_accuracy: 0.9442\n",
            "Epoch 7/10\n",
            "84/84 [==============================] - 7s 88ms/step - loss: 0.0157 - accuracy: 0.9959 - val_loss: 0.1703 - val_accuracy: 0.9639\n",
            "Epoch 8/10\n",
            "84/84 [==============================] - 7s 88ms/step - loss: 0.0705 - accuracy: 0.9780 - val_loss: 0.1749 - val_accuracy: 0.9526\n",
            "Epoch 9/10\n",
            "84/84 [==============================] - 8s 90ms/step - loss: 0.0226 - accuracy: 0.9923 - val_loss: 0.1564 - val_accuracy: 0.9628\n",
            "Epoch 10/10\n",
            "84/84 [==============================] - 7s 87ms/step - loss: 0.0164 - accuracy: 0.9957 - val_loss: 0.1692 - val_accuracy: 0.9600\n",
            "56/56 [==============================] - 1s 16ms/step - loss: 0.2050 - accuracy: 0.9532\n",
            "Test Accuracy: 0.9531866908073425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess the image\n",
        "image = cv2.imread('/content/IMG0002741.jpg')\n",
        "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
        "resized_image = cv2.resize(gray_image, (225, 225))    # Resize to the same dimensions used during training\n",
        "\n",
        "# Make prediction\n",
        "prediction = model.predict(np.expand_dims(resized_image, axis=0))\n",
        "\n",
        "# Interpret the prediction\n",
        "if prediction[0] >= 0.5:\n",
        "    print(\"The bone contains a fracture.\")\n",
        "else:\n",
        "    print(\"The bone does not contain a fracture.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wZHersc_8ek",
        "outputId": "d5c014af-f278-45c9-fc75-47391494fe9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "The bone contains a fracture.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('bone_fracture_model')"
      ],
      "metadata": {
        "id": "rYPzan2Yc2Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/bone_fracture_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-sbA8iTlP-e",
        "outputId": "c87ec171-7a07-41e4-c463-baa9bb61edf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IznkA8b0maAN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}